{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data1/hadoop/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /data1/hadoop/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /data1/hadoop/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /data1/hadoop/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Iter: 0; D loss: 0.006517; G_loss: 0.007201\n",
      "Iter: 100; D loss: 1.984; G_loss: 1.516\n",
      "Iter: 200; D loss: 1.864; G_loss: 1.355\n",
      "Iter: 300; D loss: 1.635; G_loss: 1.055\n",
      "Iter: 400; D loss: 1.329; G_loss: 0.8953\n",
      "Iter: 500; D loss: 1.06; G_loss: 0.8179\n",
      "Iter: 600; D loss: 0.676; G_loss: 0.6732\n",
      "Iter: 700; D loss: 0.4882; G_loss: 0.534\n",
      "Iter: 800; D loss: 0.3102; G_loss: 0.456\n",
      "Iter: 900; D loss: 0.1561; G_loss: 0.2433\n",
      "Iter: 1000; D loss: 0.08817; G_loss: 0.06849\n",
      "Iter: 1100; D loss: 0.06524; G_loss: 0.08299\n",
      "Iter: 1200; D loss: 0.02315; G_loss: -0.008107\n",
      "Iter: 1300; D loss: 0.00727; G_loss: -0.0479\n",
      "Iter: 1400; D loss: 0.01127; G_loss: -0.03191\n",
      "Iter: 1500; D loss: 0.005008; G_loss: -0.08377\n",
      "Iter: 1600; D loss: 0.007955; G_loss: 0.009252\n",
      "Iter: 1700; D loss: 0.004149; G_loss: 0.05162\n",
      "Iter: 1800; D loss: 0.00902; G_loss: 0.05705\n",
      "Iter: 1900; D loss: 0.002801; G_loss: -0.001562\n",
      "Iter: 2000; D loss: -0.004035; G_loss: -0.01757\n",
      "Iter: 2100; D loss: 0.01036; G_loss: -0.07107\n",
      "Iter: 2200; D loss: 0.001253; G_loss: -0.02916\n",
      "Iter: 2300; D loss: 0.003748; G_loss: -0.01312\n",
      "Iter: 2400; D loss: 0.003209; G_loss: -0.03919\n",
      "Iter: 2500; D loss: 0.005891; G_loss: -0.04126\n",
      "Iter: 2600; D loss: 0.0009575; G_loss: 0.05757\n",
      "Iter: 2700; D loss: -0.009327; G_loss: -0.09904\n",
      "Iter: 2800; D loss: 0.003792; G_loss: -0.0129\n",
      "Iter: 2900; D loss: 0.002669; G_loss: 0.001819\n",
      "Iter: 3000; D loss: -0.008125; G_loss: -0.1038\n",
      "Iter: 3100; D loss: 0.005963; G_loss: -0.007658\n",
      "Iter: 3200; D loss: 0.005474; G_loss: -0.02347\n",
      "Iter: 3300; D loss: 0.002851; G_loss: 0.1036\n",
      "Iter: 3400; D loss: 0.01364; G_loss: 0.09602\n",
      "Iter: 3500; D loss: 0.006681; G_loss: 0.05052\n",
      "Iter: 3600; D loss: 0.006733; G_loss: 0.03312\n",
      "Iter: 3700; D loss: 0.009156; G_loss: -0.02355\n",
      "Iter: 3800; D loss: 0.00686; G_loss: -0.04466\n",
      "Iter: 3900; D loss: 0.01473; G_loss: -0.02248\n",
      "Iter: 4000; D loss: 0.03074; G_loss: -0.02337\n",
      "Iter: 4100; D loss: 0.03924; G_loss: -0.01751\n",
      "Iter: 4200; D loss: 0.04168; G_loss: -0.01659\n",
      "Iter: 4300; D loss: 0.04195; G_loss: -0.02636\n",
      "Iter: 4400; D loss: 0.04519; G_loss: -0.06732\n",
      "Iter: 4500; D loss: 0.04876; G_loss: -0.07562\n",
      "Iter: 4600; D loss: 0.04404; G_loss: 0.006205\n",
      "Iter: 4700; D loss: 0.03975; G_loss: 0.06353\n",
      "Iter: 4800; D loss: 0.04977; G_loss: 0.02186\n",
      "Iter: 4900; D loss: 0.06157; G_loss: 0.009709\n",
      "Iter: 5000; D loss: 0.04732; G_loss: -0.04974\n",
      "Iter: 5100; D loss: 0.04008; G_loss: 0.02162\n",
      "Iter: 5200; D loss: 0.03782; G_loss: -0.00598\n",
      "Iter: 5300; D loss: 0.04502; G_loss: -0.04128\n",
      "Iter: 5400; D loss: 0.05092; G_loss: -0.04132\n",
      "Iter: 5500; D loss: 0.03977; G_loss: -0.008115\n",
      "Iter: 5600; D loss: 0.05145; G_loss: -0.03371\n",
      "Iter: 5700; D loss: 0.05561; G_loss: -0.03088\n",
      "Iter: 5800; D loss: 0.04896; G_loss: -0.01495\n",
      "Iter: 5900; D loss: 0.0404; G_loss: 0.004424\n",
      "Iter: 6000; D loss: 0.0498; G_loss: -0.02713\n",
      "Iter: 6100; D loss: 0.04; G_loss: -0.01813\n",
      "Iter: 6200; D loss: 0.04359; G_loss: -0.006221\n",
      "Iter: 6300; D loss: 0.05129; G_loss: -0.02439\n",
      "Iter: 6400; D loss: 0.05216; G_loss: -0.001665\n",
      "Iter: 6500; D loss: 0.05908; G_loss: -0.02116\n",
      "Iter: 6600; D loss: 0.04976; G_loss: -0.00447\n",
      "Iter: 6700; D loss: 0.05104; G_loss: -0.00979\n",
      "Iter: 6800; D loss: 0.04171; G_loss: -0.02084\n",
      "Iter: 6900; D loss: 0.05141; G_loss: -0.03011\n",
      "Iter: 7000; D loss: 0.04702; G_loss: -0.01627\n",
      "Iter: 7100; D loss: 0.03814; G_loss: -0.01514\n",
      "Iter: 7200; D loss: 0.0432; G_loss: -0.01595\n",
      "Iter: 7300; D loss: 0.03954; G_loss: -0.009865\n",
      "Iter: 7400; D loss: 0.03851; G_loss: 0.008903\n",
      "Iter: 7500; D loss: 0.04092; G_loss: -0.0118\n",
      "Iter: 7600; D loss: 0.04709; G_loss: -0.007237\n",
      "Iter: 7700; D loss: 0.05237; G_loss: -0.007372\n",
      "Iter: 7800; D loss: 0.05052; G_loss: -0.006238\n",
      "Iter: 7900; D loss: 0.04328; G_loss: 0.004706\n",
      "Iter: 8000; D loss: 0.03907; G_loss: -0.007014\n",
      "Iter: 8100; D loss: 0.04443; G_loss: -0.01021\n",
      "Iter: 8200; D loss: 0.04374; G_loss: -0.005548\n",
      "Iter: 8300; D loss: 0.0365; G_loss: -0.02381\n",
      "Iter: 8400; D loss: 0.03756; G_loss: -0.03574\n",
      "Iter: 8500; D loss: 0.04532; G_loss: -0.02413\n",
      "Iter: 8600; D loss: 0.04205; G_loss: -0.007813\n",
      "Iter: 8700; D loss: 0.0368; G_loss: -0.02376\n",
      "Iter: 8800; D loss: 0.02962; G_loss: -0.02853\n",
      "Iter: 8900; D loss: 0.04287; G_loss: -0.01684\n",
      "Iter: 9000; D loss: 0.0436; G_loss: -0.02727\n",
      "Iter: 9100; D loss: 0.03187; G_loss: -0.02003\n",
      "Iter: 9200; D loss: 0.03886; G_loss: -0.03564\n",
      "Iter: 9300; D loss: 0.03214; G_loss: -0.0254\n",
      "Iter: 9400; D loss: 0.04011; G_loss: -0.02321\n",
      "Iter: 9500; D loss: 0.03782; G_loss: -0.03449\n",
      "Iter: 9600; D loss: 0.03741; G_loss: -0.01892\n",
      "Iter: 9700; D loss: 0.03239; G_loss: -0.01075\n",
      "Iter: 9800; D loss: 0.0373; G_loss: -0.01686\n",
      "Iter: 9900; D loss: 0.03213; G_loss: -0.01895\n",
      "Iter: 10000; D loss: 0.03337; G_loss: -0.02538\n",
      "Iter: 10100; D loss: 0.03377; G_loss: -0.02492\n",
      "Iter: 10200; D loss: 0.04343; G_loss: -0.0204\n",
      "Iter: 10300; D loss: 0.0313; G_loss: -0.02917\n",
      "Iter: 10400; D loss: 0.03376; G_loss: -0.02109\n",
      "Iter: 10500; D loss: 0.03285; G_loss: -0.02868\n",
      "Iter: 10600; D loss: 0.03471; G_loss: -0.04276\n",
      "Iter: 10700; D loss: 0.03378; G_loss: -0.0275\n",
      "Iter: 10800; D loss: 0.03554; G_loss: -0.02658\n",
      "Iter: 10900; D loss: 0.02873; G_loss: -0.01999\n",
      "Iter: 11000; D loss: 0.02641; G_loss: -0.02088\n",
      "Iter: 11100; D loss: 0.03196; G_loss: -0.02332\n",
      "Iter: 11200; D loss: 0.03466; G_loss: -0.01753\n",
      "Iter: 11300; D loss: 0.0351; G_loss: -0.02739\n",
      "Iter: 11400; D loss: 0.03209; G_loss: -0.02464\n",
      "Iter: 11500; D loss: 0.03289; G_loss: -0.02772\n",
      "Iter: 11600; D loss: 0.0309; G_loss: -0.02796\n",
      "Iter: 11700; D loss: 0.02767; G_loss: -0.03044\n",
      "Iter: 11800; D loss: 0.02697; G_loss: -0.03439\n",
      "Iter: 11900; D loss: 0.02836; G_loss: -0.006499\n",
      "Iter: 12000; D loss: 0.02791; G_loss: -0.00553\n",
      "Iter: 12100; D loss: 0.03094; G_loss: -0.03111\n",
      "Iter: 12200; D loss: 0.02131; G_loss: -0.01653\n",
      "Iter: 12300; D loss: 0.02722; G_loss: -0.02035\n",
      "Iter: 12400; D loss: 0.03526; G_loss: -0.02592\n",
      "Iter: 12500; D loss: 0.0372; G_loss: -0.01859\n",
      "Iter: 12600; D loss: 0.03124; G_loss: -0.01037\n",
      "Iter: 12700; D loss: 0.03067; G_loss: -0.01489\n",
      "Iter: 12800; D loss: 0.03404; G_loss: -0.02046\n",
      "Iter: 12900; D loss: 0.03203; G_loss: -0.02094\n",
      "Iter: 13000; D loss: 0.02783; G_loss: -0.03735\n",
      "Iter: 13100; D loss: 0.0275; G_loss: -0.009201\n",
      "Iter: 13200; D loss: 0.02926; G_loss: -0.02952\n",
      "Iter: 13300; D loss: 0.03178; G_loss: -0.03088\n",
      "Iter: 13400; D loss: 0.03252; G_loss: 0.000769\n",
      "Iter: 13500; D loss: 0.03054; G_loss: -0.02078\n",
      "Iter: 13600; D loss: 0.03318; G_loss: -0.01681\n",
      "Iter: 13700; D loss: 0.03052; G_loss: -0.01459\n",
      "Iter: 13800; D loss: 0.02247; G_loss: -0.02843\n",
      "Iter: 13900; D loss: 0.03109; G_loss: -0.01392\n",
      "Iter: 14000; D loss: 0.02444; G_loss: -0.02894\n",
      "Iter: 14100; D loss: 0.02652; G_loss: -0.02259\n",
      "Iter: 14200; D loss: 0.02557; G_loss: -0.02609\n",
      "Iter: 14300; D loss: 0.03061; G_loss: -0.03238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 14400; D loss: 0.0266; G_loss: -0.01701\n",
      "Iter: 14500; D loss: 0.02668; G_loss: -0.008355\n",
      "Iter: 14600; D loss: 0.03045; G_loss: -0.00787\n",
      "Iter: 14700; D loss: 0.03075; G_loss: 9.134e-05\n",
      "Iter: 14800; D loss: 0.02201; G_loss: -0.01707\n",
      "Iter: 14900; D loss: 0.03015; G_loss: -0.0103\n",
      "Iter: 15000; D loss: 0.0267; G_loss: -0.002375\n",
      "Iter: 15100; D loss: 0.02821; G_loss: -0.01009\n",
      "Iter: 15200; D loss: 0.02116; G_loss: -0.02826\n",
      "Iter: 15300; D loss: 0.02556; G_loss: -0.02265\n",
      "Iter: 15400; D loss: 0.02555; G_loss: -0.005669\n",
      "Iter: 15500; D loss: 0.03007; G_loss: -0.0181\n",
      "Iter: 15600; D loss: 0.02052; G_loss: -0.02252\n",
      "Iter: 15700; D loss: 0.02256; G_loss: -0.01257\n",
      "Iter: 15800; D loss: 0.02379; G_loss: -0.01389\n",
      "Iter: 15900; D loss: 0.0259; G_loss: -0.01617\n",
      "Iter: 16000; D loss: 0.02631; G_loss: -0.01276\n",
      "Iter: 16100; D loss: 0.02224; G_loss: -0.01286\n",
      "Iter: 16200; D loss: 0.02079; G_loss: -9.298e-05\n",
      "Iter: 16300; D loss: 0.0243; G_loss: -0.01351\n",
      "Iter: 16400; D loss: 0.02318; G_loss: -0.02037\n",
      "Iter: 16500; D loss: 0.02986; G_loss: -0.002991\n",
      "Iter: 16600; D loss: 0.02266; G_loss: -0.02397\n",
      "Iter: 16700; D loss: 0.02409; G_loss: -0.04119\n",
      "Iter: 16800; D loss: 0.02184; G_loss: -0.02517\n",
      "Iter: 16900; D loss: 0.02938; G_loss: -0.00691\n",
      "Iter: 17000; D loss: 0.0238; G_loss: -0.01871\n",
      "Iter: 17100; D loss: 0.02334; G_loss: -0.02877\n",
      "Iter: 17200; D loss: 0.03096; G_loss: -0.02931\n",
      "Iter: 17300; D loss: 0.02764; G_loss: -0.01919\n",
      "Iter: 17400; D loss: 0.02443; G_loss: -0.005564\n",
      "Iter: 17500; D loss: 0.02422; G_loss: -0.01249\n",
      "Iter: 17600; D loss: 0.02336; G_loss: -0.02822\n",
      "Iter: 17700; D loss: 0.02778; G_loss: -0.02213\n",
      "Iter: 17800; D loss: 0.02262; G_loss: -0.02753\n",
      "Iter: 17900; D loss: 0.02515; G_loss: -0.02217\n",
      "Iter: 18000; D loss: 0.02249; G_loss: -0.02646\n",
      "Iter: 18100; D loss: 0.01841; G_loss: -0.02215\n",
      "Iter: 18200; D loss: 0.02316; G_loss: -0.01299\n",
      "Iter: 18300; D loss: 0.02458; G_loss: -0.02072\n",
      "Iter: 18400; D loss: 0.02316; G_loss: -0.004752\n",
      "Iter: 18500; D loss: 0.02173; G_loss: -0.04348\n",
      "Iter: 18600; D loss: 0.02299; G_loss: -0.01123\n",
      "Iter: 18700; D loss: 0.0204; G_loss: -0.02926\n",
      "Iter: 18800; D loss: 0.02574; G_loss: -0.01059\n",
      "Iter: 18900; D loss: 0.0266; G_loss: -0.02872\n",
      "Iter: 19000; D loss: 0.02469; G_loss: -0.03062\n",
      "Iter: 19100; D loss: 0.02389; G_loss: -0.03478\n",
      "Iter: 19200; D loss: 0.02361; G_loss: -0.02325\n",
      "Iter: 19300; D loss: 0.02349; G_loss: -0.0161\n",
      "Iter: 19400; D loss: 0.01787; G_loss: -0.01892\n",
      "Iter: 19500; D loss: 0.02066; G_loss: -0.02805\n",
      "Iter: 19600; D loss: 0.02252; G_loss: -0.02456\n",
      "Iter: 19700; D loss: 0.01905; G_loss: -0.0143\n",
      "Iter: 19800; D loss: 0.0223; G_loss: -0.02399\n",
      "Iter: 19900; D loss: 0.01914; G_loss: -0.01346\n",
      "Iter: 20000; D loss: 0.02217; G_loss: -0.02438\n",
      "Iter: 20100; D loss: 0.02024; G_loss: -0.0324\n",
      "Iter: 20200; D loss: 0.0201; G_loss: -0.02214\n",
      "Iter: 20300; D loss: 0.01882; G_loss: -0.02476\n",
      "Iter: 20400; D loss: 0.01576; G_loss: -0.0248\n",
      "Iter: 20500; D loss: 0.02347; G_loss: -0.02025\n",
      "Iter: 20600; D loss: 0.01794; G_loss: -0.02398\n",
      "Iter: 20700; D loss: 0.01318; G_loss: -0.02814\n",
      "Iter: 20800; D loss: 0.02562; G_loss: -0.03409\n",
      "Iter: 20900; D loss: 0.01785; G_loss: -0.02745\n",
      "Iter: 21000; D loss: 0.01732; G_loss: -0.02183\n",
      "Iter: 21100; D loss: 0.02063; G_loss: -0.02944\n",
      "Iter: 21200; D loss: 0.02427; G_loss: -0.02203\n",
      "Iter: 21300; D loss: 0.01893; G_loss: -0.02198\n",
      "Iter: 21400; D loss: 0.02206; G_loss: -0.03141\n",
      "Iter: 21500; D loss: 0.01709; G_loss: -0.02398\n",
      "Iter: 21600; D loss: 0.02121; G_loss: -0.01848\n",
      "Iter: 21700; D loss: 0.01637; G_loss: -0.02381\n",
      "Iter: 21800; D loss: 0.01712; G_loss: -0.02083\n",
      "Iter: 21900; D loss: 0.022; G_loss: -0.03625\n",
      "Iter: 22000; D loss: 0.0212; G_loss: -0.02339\n",
      "Iter: 22100; D loss: 0.02237; G_loss: -0.04686\n",
      "Iter: 22200; D loss: 0.01774; G_loss: -0.01589\n",
      "Iter: 22300; D loss: 0.02022; G_loss: -0.02171\n",
      "Iter: 22400; D loss: 0.02194; G_loss: -0.02595\n",
      "Iter: 22500; D loss: 0.02079; G_loss: -0.01921\n",
      "Iter: 22600; D loss: 0.02364; G_loss: -0.02848\n",
      "Iter: 22700; D loss: 0.01701; G_loss: -0.01507\n",
      "Iter: 22800; D loss: 0.01635; G_loss: -0.009479\n",
      "Iter: 22900; D loss: 0.01616; G_loss: -0.03859\n",
      "Iter: 23000; D loss: 0.02235; G_loss: -0.02553\n",
      "Iter: 23100; D loss: 0.01753; G_loss: -0.01961\n",
      "Iter: 23200; D loss: 0.01813; G_loss: -0.02279\n",
      "Iter: 23300; D loss: 0.0207; G_loss: -0.02037\n",
      "Iter: 23400; D loss: 0.01668; G_loss: -0.03206\n",
      "Iter: 23500; D loss: 0.01573; G_loss: -0.02446\n",
      "Iter: 23600; D loss: 0.0198; G_loss: -0.01103\n",
      "Iter: 23700; D loss: 0.02304; G_loss: -0.0285\n",
      "Iter: 23800; D loss: 0.01446; G_loss: -0.02614\n",
      "Iter: 23900; D loss: 0.01721; G_loss: -0.002054\n",
      "Iter: 24000; D loss: 0.01864; G_loss: -0.03487\n",
      "Iter: 24100; D loss: 0.01841; G_loss: -0.01929\n",
      "Iter: 24200; D loss: 0.01831; G_loss: -0.03317\n",
      "Iter: 24300; D loss: 0.02316; G_loss: -0.03029\n",
      "Iter: 24400; D loss: 0.01519; G_loss: -0.02626\n",
      "Iter: 24500; D loss: 0.01811; G_loss: -0.01804\n",
      "Iter: 24600; D loss: 0.01566; G_loss: -0.02976\n",
      "Iter: 24700; D loss: 0.01804; G_loss: -0.01511\n",
      "Iter: 24800; D loss: 0.02209; G_loss: -0.03273\n",
      "Iter: 24900; D loss: 0.01679; G_loss: -0.03211\n",
      "Iter: 25000; D loss: 0.02064; G_loss: -0.026\n",
      "Iter: 25100; D loss: 0.01666; G_loss: -0.02224\n",
      "Iter: 25200; D loss: 0.01842; G_loss: -0.02436\n",
      "Iter: 25300; D loss: 0.01929; G_loss: -0.02335\n",
      "Iter: 25400; D loss: 0.01716; G_loss: -0.02445\n",
      "Iter: 25500; D loss: 0.01921; G_loss: -0.03497\n",
      "Iter: 25600; D loss: 0.01729; G_loss: -0.006081\n",
      "Iter: 25700; D loss: 0.01836; G_loss: -0.0234\n",
      "Iter: 25800; D loss: 0.01982; G_loss: -0.01494\n",
      "Iter: 25900; D loss: 0.01624; G_loss: -0.02174\n",
      "Iter: 26000; D loss: 0.02316; G_loss: -0.04297\n",
      "Iter: 26100; D loss: 0.01698; G_loss: -0.02495\n",
      "Iter: 26200; D loss: 0.01669; G_loss: -0.0379\n",
      "Iter: 26300; D loss: 0.01946; G_loss: -0.03029\n",
      "Iter: 26400; D loss: 0.01506; G_loss: -0.009147\n",
      "Iter: 26500; D loss: 0.01926; G_loss: -0.02036\n",
      "Iter: 26600; D loss: 0.0174; G_loss: -0.0265\n",
      "Iter: 26700; D loss: 0.0203; G_loss: -0.02114\n",
      "Iter: 26800; D loss: 0.01423; G_loss: -0.03072\n",
      "Iter: 26900; D loss: 0.01522; G_loss: -0.0222\n",
      "Iter: 27000; D loss: 0.01859; G_loss: -0.01419\n",
      "Iter: 27100; D loss: 0.01331; G_loss: -0.01761\n",
      "Iter: 27200; D loss: 0.01583; G_loss: -0.02964\n",
      "Iter: 27300; D loss: 0.01593; G_loss: -0.009115\n",
      "Iter: 27400; D loss: 0.01811; G_loss: -0.02891\n",
      "Iter: 27500; D loss: 0.01447; G_loss: -0.02426\n",
      "Iter: 27600; D loss: 0.0131; G_loss: -0.02635\n",
      "Iter: 27700; D loss: 0.01875; G_loss: -0.02284\n",
      "Iter: 27800; D loss: 0.01696; G_loss: -0.02862\n",
      "Iter: 27900; D loss: 0.01613; G_loss: -0.01212\n",
      "Iter: 28000; D loss: 0.01975; G_loss: -0.02711\n",
      "Iter: 28100; D loss: 0.01966; G_loss: -0.01516\n",
      "Iter: 28200; D loss: 0.01747; G_loss: -0.01954\n",
      "Iter: 28300; D loss: 0.01523; G_loss: -0.0163\n",
      "Iter: 28400; D loss: 0.01836; G_loss: -0.01668\n",
      "Iter: 28500; D loss: 0.01418; G_loss: -0.02076\n",
      "Iter: 28600; D loss: 0.01713; G_loss: -0.03111\n",
      "Iter: 28700; D loss: 0.01621; G_loss: -0.02112\n",
      "Iter: 28800; D loss: 0.01666; G_loss: -0.03709\n",
      "Iter: 28900; D loss: 0.01329; G_loss: -0.01628\n",
      "Iter: 29000; D loss: 0.008849; G_loss: -0.0432\n",
      "Iter: 29100; D loss: 0.01544; G_loss: -0.03638\n",
      "Iter: 29200; D loss: 0.01749; G_loss: -0.01774\n",
      "Iter: 29300; D loss: 0.01738; G_loss: -0.003826\n",
      "Iter: 29400; D loss: 0.01508; G_loss: -0.03905\n",
      "Iter: 29500; D loss: 0.01771; G_loss: -0.02514\n",
      "Iter: 29600; D loss: 0.01789; G_loss: -0.03231\n",
      "Iter: 29700; D loss: 0.01338; G_loss: -0.008698\n",
      "Iter: 29800; D loss: 0.01588; G_loss: -0.02551\n",
      "Iter: 29900; D loss: 0.0172; G_loss: -0.02674\n",
      "Iter: 30000; D loss: 0.01564; G_loss: -0.02775\n",
      "Iter: 30100; D loss: 0.01358; G_loss: -0.02097\n",
      "Iter: 30200; D loss: 0.01516; G_loss: -0.03404\n",
      "Iter: 30300; D loss: 0.02068; G_loss: -0.02325\n",
      "Iter: 30400; D loss: 0.01903; G_loss: -0.02081\n",
      "Iter: 30500; D loss: 0.01808; G_loss: -0.03016\n",
      "Iter: 30600; D loss: 0.01443; G_loss: -0.01998\n",
      "Iter: 30700; D loss: 0.01758; G_loss: -0.02129\n",
      "Iter: 30800; D loss: 0.01188; G_loss: -0.03133\n",
      "Iter: 30900; D loss: 0.01889; G_loss: -0.02169\n",
      "Iter: 31000; D loss: 0.01614; G_loss: -0.04577\n",
      "Iter: 31100; D loss: 0.01429; G_loss: -0.02493\n",
      "Iter: 31200; D loss: 0.01839; G_loss: -0.03589\n",
      "Iter: 31300; D loss: 0.01366; G_loss: -0.02044\n",
      "Iter: 31400; D loss: 0.01509; G_loss: -0.03617\n",
      "Iter: 31500; D loss: 0.01884; G_loss: -0.003657\n",
      "Iter: 31600; D loss: 0.018; G_loss: -0.02184\n",
      "Iter: 31700; D loss: 0.012; G_loss: -0.028\n",
      "Iter: 31800; D loss: 0.01577; G_loss: -0.02428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 31900; D loss: 0.01382; G_loss: -0.02887\n",
      "Iter: 32000; D loss: 0.0182; G_loss: -0.0238\n",
      "Iter: 32100; D loss: 0.01587; G_loss: -0.01174\n",
      "Iter: 32200; D loss: 0.01688; G_loss: -0.02124\n",
      "Iter: 32300; D loss: 0.01295; G_loss: -0.03987\n",
      "Iter: 32400; D loss: 0.01549; G_loss: -0.02778\n",
      "Iter: 32500; D loss: 0.01221; G_loss: -0.02449\n",
      "Iter: 32600; D loss: 0.01789; G_loss: -0.009493\n",
      "Iter: 32700; D loss: 0.015; G_loss: -0.03379\n",
      "Iter: 32800; D loss: 0.01039; G_loss: -0.01607\n",
      "Iter: 32900; D loss: 0.01392; G_loss: -0.03047\n",
      "Iter: 33000; D loss: 0.01653; G_loss: -0.01969\n",
      "Iter: 33100; D loss: 0.0128; G_loss: -0.01615\n",
      "Iter: 33200; D loss: 0.01422; G_loss: -0.01935\n",
      "Iter: 33300; D loss: 0.01234; G_loss: -0.02347\n",
      "Iter: 33400; D loss: 0.01631; G_loss: -0.02998\n",
      "Iter: 33500; D loss: 0.0128; G_loss: -0.02169\n",
      "Iter: 33600; D loss: 0.01805; G_loss: -0.03876\n",
      "Iter: 33700; D loss: 0.01551; G_loss: -0.03485\n",
      "Iter: 33800; D loss: 0.01086; G_loss: -0.02921\n",
      "Iter: 33900; D loss: 0.01724; G_loss: -0.009974\n",
      "Iter: 34000; D loss: 0.01531; G_loss: -0.01486\n",
      "Iter: 34100; D loss: 0.01505; G_loss: -0.02064\n",
      "Iter: 34200; D loss: 0.01316; G_loss: -0.02418\n",
      "Iter: 34300; D loss: 0.009951; G_loss: -0.03303\n",
      "Iter: 34400; D loss: 0.01462; G_loss: -0.01982\n",
      "Iter: 34500; D loss: 0.01302; G_loss: -0.03061\n",
      "Iter: 34600; D loss: 0.009953; G_loss: -0.008253\n",
      "Iter: 34700; D loss: 0.01356; G_loss: -0.02638\n",
      "Iter: 34800; D loss: 0.01442; G_loss: -0.02646\n",
      "Iter: 34900; D loss: 0.01651; G_loss: -0.03226\n",
      "Iter: 35000; D loss: 0.01578; G_loss: -0.02209\n",
      "Iter: 35100; D loss: 0.01072; G_loss: -0.004499\n",
      "Iter: 35200; D loss: 0.01667; G_loss: -0.02112\n",
      "Iter: 35300; D loss: 0.01638; G_loss: -0.02668\n",
      "Iter: 35400; D loss: 0.01788; G_loss: -0.02617\n",
      "Iter: 35500; D loss: 0.01564; G_loss: -0.03944\n",
      "Iter: 35600; D loss: 0.02112; G_loss: -0.03768\n",
      "Iter: 35700; D loss: 0.0112; G_loss: -0.02063\n",
      "Iter: 35800; D loss: 0.01555; G_loss: -0.02401\n",
      "Iter: 35900; D loss: 0.01376; G_loss: -0.02609\n",
      "Iter: 36000; D loss: 0.01487; G_loss: -0.02455\n",
      "Iter: 36100; D loss: 0.01235; G_loss: -0.01158\n",
      "Iter: 36200; D loss: 0.01428; G_loss: -0.01984\n",
      "Iter: 36300; D loss: 0.01051; G_loss: -0.02024\n",
      "Iter: 36400; D loss: 0.01404; G_loss: -0.03526\n",
      "Iter: 36500; D loss: 0.01614; G_loss: -0.02145\n",
      "Iter: 36600; D loss: 0.0101; G_loss: -0.01635\n",
      "Iter: 36700; D loss: 0.01437; G_loss: -0.01685\n",
      "Iter: 36800; D loss: 0.01191; G_loss: -0.03142\n",
      "Iter: 36900; D loss: 0.0158; G_loss: -0.0275\n",
      "Iter: 37000; D loss: 0.01462; G_loss: -0.0236\n",
      "Iter: 37100; D loss: 0.01336; G_loss: -0.0198\n",
      "Iter: 37200; D loss: 0.01496; G_loss: -0.0235\n",
      "Iter: 37300; D loss: 0.01821; G_loss: -0.02071\n",
      "Iter: 37400; D loss: 0.01042; G_loss: -0.01915\n",
      "Iter: 37500; D loss: 0.0119; G_loss: -0.03101\n",
      "Iter: 37600; D loss: 0.01142; G_loss: -0.02861\n",
      "Iter: 37700; D loss: 0.01298; G_loss: -0.0158\n",
      "Iter: 37800; D loss: 0.01357; G_loss: -0.01795\n",
      "Iter: 37900; D loss: 0.01132; G_loss: -0.0269\n",
      "Iter: 38000; D loss: 0.00601; G_loss: -0.01176\n",
      "Iter: 38100; D loss: 0.01149; G_loss: -0.02548\n",
      "Iter: 38200; D loss: 0.01388; G_loss: -0.0221\n",
      "Iter: 38300; D loss: 0.01464; G_loss: -0.03073\n",
      "Iter: 38400; D loss: 0.01474; G_loss: -0.01076\n",
      "Iter: 38500; D loss: 0.01568; G_loss: -0.01597\n",
      "Iter: 38600; D loss: 0.01385; G_loss: -0.03188\n",
      "Iter: 38700; D loss: 0.01398; G_loss: -0.0236\n",
      "Iter: 38800; D loss: 0.01301; G_loss: -0.0198\n",
      "Iter: 38900; D loss: 0.01128; G_loss: -0.03378\n",
      "Iter: 39000; D loss: 0.01409; G_loss: -0.002212\n",
      "Iter: 39100; D loss: 0.01494; G_loss: -0.02477\n",
      "Iter: 39200; D loss: 0.01171; G_loss: -0.02466\n",
      "Iter: 39300; D loss: 0.01475; G_loss: 0.0001527\n",
      "Iter: 39400; D loss: 0.01353; G_loss: -0.0122\n",
      "Iter: 39500; D loss: 0.01288; G_loss: -0.02461\n",
      "Iter: 39600; D loss: 0.01654; G_loss: -0.03189\n",
      "Iter: 39700; D loss: 0.01838; G_loss: -0.01083\n",
      "Iter: 39800; D loss: 0.01015; G_loss: -0.02032\n",
      "Iter: 39900; D loss: 0.01584; G_loss: -0.03558\n",
      "Iter: 40000; D loss: 0.01489; G_loss: -0.01137\n",
      "Iter: 40100; D loss: 0.01351; G_loss: -0.02832\n",
      "Iter: 40200; D loss: 0.01476; G_loss: -0.009948\n",
      "Iter: 40300; D loss: 0.01144; G_loss: -0.01386\n",
      "Iter: 40400; D loss: 0.01238; G_loss: -0.0214\n",
      "Iter: 40500; D loss: 0.01202; G_loss: -0.01778\n",
      "Iter: 40600; D loss: 0.01073; G_loss: -0.03234\n",
      "Iter: 40700; D loss: 0.01407; G_loss: -0.01236\n",
      "Iter: 40800; D loss: 0.01394; G_loss: -0.03566\n",
      "Iter: 40900; D loss: 0.01266; G_loss: -0.02545\n",
      "Iter: 41000; D loss: 0.01434; G_loss: -0.01929\n",
      "Iter: 41100; D loss: 0.01193; G_loss: -0.01967\n",
      "Iter: 41200; D loss: 0.01417; G_loss: -0.02691\n",
      "Iter: 41300; D loss: 0.01139; G_loss: -0.01963\n",
      "Iter: 41400; D loss: 0.01311; G_loss: -0.01236\n",
      "Iter: 41500; D loss: 0.01566; G_loss: -0.02523\n",
      "Iter: 41600; D loss: 0.0106; G_loss: -0.02815\n",
      "Iter: 41700; D loss: 0.01857; G_loss: -0.01901\n",
      "Iter: 41800; D loss: 0.01134; G_loss: -0.0279\n",
      "Iter: 41900; D loss: 0.01685; G_loss: -0.02823\n",
      "Iter: 42000; D loss: 0.01706; G_loss: -0.008332\n",
      "Iter: 42100; D loss: 0.01347; G_loss: -0.01906\n",
      "Iter: 42200; D loss: 0.01398; G_loss: -0.02731\n",
      "Iter: 42300; D loss: 0.01278; G_loss: -0.02399\n",
      "Iter: 42400; D loss: 0.009137; G_loss: -0.004745\n",
      "Iter: 42500; D loss: 0.015; G_loss: -0.01937\n",
      "Iter: 42600; D loss: 0.01223; G_loss: -0.03145\n",
      "Iter: 42700; D loss: 0.01264; G_loss: -0.01608\n",
      "Iter: 42800; D loss: 0.01235; G_loss: -0.02205\n",
      "Iter: 42900; D loss: 0.009587; G_loss: -0.02057\n",
      "Iter: 43000; D loss: 0.01455; G_loss: -0.01753\n",
      "Iter: 43100; D loss: 0.01357; G_loss: -0.03325\n",
      "Iter: 43200; D loss: 0.01502; G_loss: -0.004125\n",
      "Iter: 43300; D loss: 0.009487; G_loss: -0.02957\n",
      "Iter: 43400; D loss: 0.01631; G_loss: -0.01634\n",
      "Iter: 43500; D loss: 0.009928; G_loss: -0.02443\n",
      "Iter: 43600; D loss: 0.01046; G_loss: -0.02552\n",
      "Iter: 43700; D loss: 0.01169; G_loss: -0.0271\n",
      "Iter: 43800; D loss: 0.01292; G_loss: -0.01453\n",
      "Iter: 43900; D loss: 0.009191; G_loss: -0.03034\n",
      "Iter: 44000; D loss: 0.009864; G_loss: -0.02521\n",
      "Iter: 44100; D loss: 0.01493; G_loss: -0.02312\n",
      "Iter: 44200; D loss: 0.02073; G_loss: -0.02657\n",
      "Iter: 44300; D loss: 0.0183; G_loss: -0.02193\n",
      "Iter: 44400; D loss: 0.01948; G_loss: -0.02839\n",
      "Iter: 44500; D loss: 0.0168; G_loss: -0.01892\n",
      "Iter: 44600; D loss: 0.01966; G_loss: -0.02146\n",
      "Iter: 44700; D loss: 0.02018; G_loss: -0.01619\n",
      "Iter: 44800; D loss: 0.01447; G_loss: -0.02549\n",
      "Iter: 44900; D loss: 0.01552; G_loss: -0.01775\n",
      "Iter: 45000; D loss: 0.01739; G_loss: -0.01883\n",
      "Iter: 45100; D loss: 0.01941; G_loss: -0.02298\n",
      "Iter: 45200; D loss: 0.02347; G_loss: -0.02413\n",
      "Iter: 45300; D loss: 0.01864; G_loss: -0.02076\n",
      "Iter: 45400; D loss: 0.01549; G_loss: -0.02068\n",
      "Iter: 45500; D loss: 0.0172; G_loss: -0.01966\n",
      "Iter: 45600; D loss: 0.01686; G_loss: -0.01926\n",
      "Iter: 45700; D loss: 0.01613; G_loss: -0.01994\n",
      "Iter: 45800; D loss: 0.01475; G_loss: -0.02215\n",
      "Iter: 45900; D loss: 0.01603; G_loss: -0.01827\n",
      "Iter: 46000; D loss: 0.01895; G_loss: -0.01568\n",
      "Iter: 46100; D loss: 0.01677; G_loss: -0.01805\n",
      "Iter: 46200; D loss: 0.01434; G_loss: -0.01888\n",
      "Iter: 46300; D loss: 0.01706; G_loss: -0.01722\n",
      "Iter: 46400; D loss: 0.01695; G_loss: -0.02098\n",
      "Iter: 46500; D loss: 0.01505; G_loss: -0.0183\n",
      "Iter: 46600; D loss: 0.01304; G_loss: -0.02362\n",
      "Iter: 46700; D loss: 0.01771; G_loss: -0.02016\n",
      "Iter: 46800; D loss: 0.02134; G_loss: -0.02492\n",
      "Iter: 46900; D loss: 0.01963; G_loss: -0.02003\n",
      "Iter: 47000; D loss: 0.01941; G_loss: -0.02141\n",
      "Iter: 47100; D loss: 0.0123; G_loss: -0.02088\n",
      "Iter: 47200; D loss: 0.0188; G_loss: -0.02248\n",
      "Iter: 47300; D loss: 0.01793; G_loss: -0.01724\n",
      "Iter: 47400; D loss: 0.01426; G_loss: -0.01224\n",
      "Iter: 47500; D loss: 0.01632; G_loss: -0.0211\n",
      "Iter: 47600; D loss: 0.01528; G_loss: -0.0179\n",
      "Iter: 47700; D loss: 0.01657; G_loss: -0.02059\n",
      "Iter: 47800; D loss: 0.01948; G_loss: -0.01734\n",
      "Iter: 47900; D loss: 0.01535; G_loss: -0.01361\n",
      "Iter: 48000; D loss: 0.01509; G_loss: -0.0136\n",
      "Iter: 48100; D loss: 0.01612; G_loss: -0.0151\n",
      "Iter: 48200; D loss: 0.01855; G_loss: -0.01671\n",
      "Iter: 48300; D loss: 0.01963; G_loss: -0.02271\n",
      "Iter: 48400; D loss: 0.01862; G_loss: -0.02294\n",
      "Iter: 48500; D loss: 0.01702; G_loss: -0.01648\n",
      "Iter: 48600; D loss: 0.01822; G_loss: -0.02219\n",
      "Iter: 48700; D loss: 0.01781; G_loss: -0.01471\n",
      "Iter: 48800; D loss: 0.01752; G_loss: -0.01884\n",
      "Iter: 48900; D loss: 0.01831; G_loss: -0.02094\n",
      "Iter: 49000; D loss: 0.02146; G_loss: -0.01739\n",
      "Iter: 49100; D loss: 0.01923; G_loss: -0.01893\n",
      "Iter: 49200; D loss: 0.0161; G_loss: -0.01584\n",
      "Iter: 49300; D loss: 0.01798; G_loss: -0.01497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 49400; D loss: 0.01948; G_loss: -0.01388\n",
      "Iter: 49500; D loss: 0.01763; G_loss: -0.0152\n",
      "Iter: 49600; D loss: 0.0184; G_loss: -0.01746\n",
      "Iter: 49700; D loss: 0.01697; G_loss: -0.01746\n",
      "Iter: 49800; D loss: 0.02048; G_loss: -0.01849\n",
      "Iter: 49900; D loss: 0.01268; G_loss: -0.01789\n",
      "Iter: 50000; D loss: 0.01885; G_loss: -0.01449\n",
      "Iter: 50100; D loss: 0.01705; G_loss: -0.02353\n",
      "Iter: 50200; D loss: 0.01828; G_loss: -0.01954\n",
      "Iter: 50300; D loss: 0.01457; G_loss: -0.01685\n",
      "Iter: 50400; D loss: 0.02079; G_loss: -0.01846\n",
      "Iter: 50500; D loss: 0.01367; G_loss: -0.0189\n",
      "Iter: 50600; D loss: 0.01607; G_loss: -0.01672\n",
      "Iter: 50700; D loss: 0.01677; G_loss: -0.01734\n",
      "Iter: 50800; D loss: 0.01552; G_loss: -0.01779\n",
      "Iter: 50900; D loss: 0.0178; G_loss: -0.01495\n",
      "Iter: 51000; D loss: 0.01737; G_loss: -0.01591\n",
      "Iter: 51100; D loss: 0.01818; G_loss: -0.0181\n",
      "Iter: 51200; D loss: 0.01504; G_loss: -0.01661\n",
      "Iter: 51300; D loss: 0.01596; G_loss: -0.01327\n",
      "Iter: 51400; D loss: 0.01818; G_loss: -0.02128\n",
      "Iter: 51500; D loss: 0.01795; G_loss: -0.01599\n",
      "Iter: 51600; D loss: 0.01389; G_loss: -0.01893\n",
      "Iter: 51700; D loss: 0.01493; G_loss: -0.01827\n",
      "Iter: 51800; D loss: 0.01772; G_loss: -0.01457\n",
      "Iter: 51900; D loss: 0.01547; G_loss: -0.01571\n",
      "Iter: 52000; D loss: 0.01918; G_loss: -0.01661\n",
      "Iter: 52100; D loss: 0.01972; G_loss: -0.01627\n",
      "Iter: 52200; D loss: 0.01973; G_loss: -0.01448\n",
      "Iter: 52300; D loss: 0.01676; G_loss: -0.01602\n",
      "Iter: 52400; D loss: 0.01676; G_loss: -0.01936\n",
      "Iter: 52500; D loss: 0.01771; G_loss: -0.01544\n",
      "Iter: 52600; D loss: 0.0173; G_loss: -0.01847\n",
      "Iter: 52700; D loss: 0.02049; G_loss: -0.02177\n",
      "Iter: 52800; D loss: 0.01622; G_loss: -0.01971\n",
      "Iter: 52900; D loss: 0.01539; G_loss: -0.01559\n",
      "Iter: 53000; D loss: 0.02116; G_loss: -0.01886\n",
      "Iter: 53100; D loss: 0.0159; G_loss: -0.0174\n",
      "Iter: 53200; D loss: 0.01633; G_loss: -0.01975\n",
      "Iter: 53300; D loss: 0.01643; G_loss: -0.01985\n",
      "Iter: 53400; D loss: 0.01833; G_loss: -0.02038\n",
      "Iter: 53500; D loss: 0.01589; G_loss: -0.01665\n",
      "Iter: 53600; D loss: 0.0181; G_loss: -0.01701\n",
      "Iter: 53700; D loss: 0.01203; G_loss: -0.01729\n",
      "Iter: 53800; D loss: 0.01833; G_loss: -0.0224\n",
      "Iter: 53900; D loss: 0.01367; G_loss: -0.0191\n",
      "Iter: 54000; D loss: 0.01735; G_loss: -0.01421\n",
      "Iter: 54100; D loss: 0.01717; G_loss: -0.01557\n",
      "Iter: 54200; D loss: 0.01419; G_loss: -0.02277\n",
      "Iter: 54300; D loss: 0.02044; G_loss: -0.01585\n",
      "Iter: 54400; D loss: 0.01711; G_loss: -0.01407\n",
      "Iter: 54500; D loss: 0.01373; G_loss: -0.01592\n",
      "Iter: 54600; D loss: 0.01546; G_loss: -0.01731\n",
      "Iter: 54700; D loss: 0.01682; G_loss: -0.01855\n",
      "Iter: 54800; D loss: 0.01268; G_loss: -0.01861\n",
      "Iter: 54900; D loss: 0.0139; G_loss: -0.01546\n",
      "Iter: 55000; D loss: 0.01653; G_loss: -0.01201\n",
      "Iter: 55100; D loss: 0.01662; G_loss: -0.02135\n",
      "Iter: 55200; D loss: 0.01636; G_loss: -0.01467\n",
      "Iter: 55300; D loss: 0.01674; G_loss: -0.01517\n",
      "Iter: 55400; D loss: 0.02013; G_loss: -0.02105\n",
      "Iter: 55500; D loss: 0.01683; G_loss: -0.01478\n",
      "Iter: 55600; D loss: 0.01769; G_loss: -0.01267\n",
      "Iter: 55700; D loss: 0.01145; G_loss: -0.01842\n",
      "Iter: 55800; D loss: 0.01279; G_loss: -0.01621\n",
      "Iter: 55900; D loss: 0.0155; G_loss: -0.01688\n",
      "Iter: 56000; D loss: 0.01354; G_loss: -0.0151\n",
      "Iter: 56100; D loss: 0.01555; G_loss: -0.01791\n",
      "Iter: 56200; D loss: 0.02075; G_loss: -0.01586\n",
      "Iter: 56300; D loss: 0.01705; G_loss: -0.01956\n",
      "Iter: 56400; D loss: 0.01138; G_loss: -0.02292\n",
      "Iter: 56500; D loss: 0.0173; G_loss: -0.02212\n",
      "Iter: 56600; D loss: 0.01706; G_loss: -0.01465\n",
      "Iter: 56700; D loss: 0.01488; G_loss: -0.02003\n",
      "Iter: 56800; D loss: 0.01693; G_loss: -0.01502\n",
      "Iter: 56900; D loss: 0.01369; G_loss: -0.01448\n",
      "Iter: 57000; D loss: 0.01727; G_loss: -0.01679\n",
      "Iter: 57100; D loss: 0.01629; G_loss: -0.02138\n",
      "Iter: 57200; D loss: 0.0136; G_loss: -0.01893\n",
      "Iter: 57300; D loss: 0.01716; G_loss: -0.01908\n",
      "Iter: 57400; D loss: 0.01691; G_loss: -0.02351\n",
      "Iter: 57500; D loss: 0.01589; G_loss: -0.01704\n",
      "Iter: 57600; D loss: 0.0169; G_loss: -0.01798\n",
      "Iter: 57700; D loss: 0.01698; G_loss: -0.01384\n",
      "Iter: 57800; D loss: 0.01394; G_loss: -0.01681\n",
      "Iter: 57900; D loss: 0.01674; G_loss: -0.01781\n",
      "Iter: 58000; D loss: 0.01511; G_loss: -0.01754\n",
      "Iter: 58100; D loss: 0.01473; G_loss: -0.01771\n",
      "Iter: 58200; D loss: 0.02078; G_loss: -0.01786\n",
      "Iter: 58300; D loss: 0.01872; G_loss: -0.01841\n",
      "Iter: 58400; D loss: 0.01183; G_loss: -0.01402\n",
      "Iter: 58500; D loss: 0.01416; G_loss: -0.01831\n",
      "Iter: 58600; D loss: 0.01624; G_loss: -0.01142\n",
      "Iter: 58700; D loss: 0.02063; G_loss: -0.0177\n",
      "Iter: 58800; D loss: 0.01427; G_loss: -0.01629\n",
      "Iter: 58900; D loss: 0.01516; G_loss: -0.01814\n",
      "Iter: 59000; D loss: 0.0183; G_loss: -0.01815\n",
      "Iter: 59100; D loss: 0.01836; G_loss: -0.01765\n",
      "Iter: 59200; D loss: 0.01714; G_loss: -0.01231\n",
      "Iter: 59300; D loss: 0.01523; G_loss: -0.01031\n",
      "Iter: 59400; D loss: 0.01615; G_loss: -0.01704\n",
      "Iter: 59500; D loss: 0.0113; G_loss: -0.01453\n",
      "Iter: 59600; D loss: 0.0207; G_loss: -0.01685\n",
      "Iter: 59700; D loss: 0.0172; G_loss: -0.01738\n",
      "Iter: 59800; D loss: 0.01401; G_loss: -0.01653\n",
      "Iter: 59900; D loss: 0.01425; G_loss: -0.01803\n",
      "Iter: 60000; D loss: 0.01542; G_loss: -0.01714\n",
      "Iter: 60100; D loss: 0.01475; G_loss: -0.01786\n",
      "Iter: 60200; D loss: 0.01284; G_loss: -0.01599\n",
      "Iter: 60300; D loss: 0.01386; G_loss: -0.01525\n",
      "Iter: 60400; D loss: 0.02001; G_loss: -0.02034\n",
      "Iter: 60500; D loss: 0.01399; G_loss: -0.01982\n",
      "Iter: 60600; D loss: 0.0182; G_loss: -0.01467\n",
      "Iter: 60700; D loss: 0.01703; G_loss: -0.01499\n",
      "Iter: 60800; D loss: 0.01774; G_loss: -0.01899\n",
      "Iter: 60900; D loss: 0.01351; G_loss: -0.01454\n",
      "Iter: 61000; D loss: 0.01572; G_loss: -0.01377\n",
      "Iter: 61100; D loss: 0.009999; G_loss: -0.0168\n",
      "Iter: 61200; D loss: 0.01728; G_loss: -0.01372\n",
      "Iter: 61300; D loss: 0.01553; G_loss: -0.01606\n",
      "Iter: 61400; D loss: 0.01284; G_loss: -0.01512\n",
      "Iter: 61500; D loss: 0.01524; G_loss: -0.01537\n",
      "Iter: 61600; D loss: 0.01328; G_loss: -0.01409\n",
      "Iter: 61700; D loss: 0.01905; G_loss: -0.01846\n",
      "Iter: 61800; D loss: 0.01551; G_loss: -0.01347\n",
      "Iter: 61900; D loss: 0.01298; G_loss: -0.01508\n",
      "Iter: 62000; D loss: 0.02204; G_loss: -0.02104\n",
      "Iter: 62100; D loss: 0.01805; G_loss: -0.01916\n",
      "Iter: 62200; D loss: 0.01716; G_loss: -0.0186\n",
      "Iter: 62300; D loss: 0.01887; G_loss: -0.01632\n",
      "Iter: 62400; D loss: 0.01119; G_loss: -0.0172\n",
      "Iter: 62500; D loss: 0.01941; G_loss: -0.01509\n",
      "Iter: 62600; D loss: 0.01386; G_loss: -0.01503\n",
      "Iter: 62700; D loss: 0.01418; G_loss: -0.0195\n",
      "Iter: 62800; D loss: 0.01169; G_loss: -0.01383\n",
      "Iter: 62900; D loss: 0.01693; G_loss: -0.01927\n",
      "Iter: 63000; D loss: 0.01669; G_loss: -0.01803\n",
      "Iter: 63100; D loss: 0.01563; G_loss: -0.01648\n",
      "Iter: 63200; D loss: 0.01606; G_loss: -0.01738\n",
      "Iter: 63300; D loss: 0.01686; G_loss: -0.01511\n",
      "Iter: 63400; D loss: 0.016; G_loss: -0.01662\n",
      "Iter: 63500; D loss: 0.0163; G_loss: -0.01232\n",
      "Iter: 63600; D loss: 0.01455; G_loss: -0.01727\n",
      "Iter: 63700; D loss: 0.0137; G_loss: -0.01793\n",
      "Iter: 63800; D loss: 0.0143; G_loss: -0.01903\n",
      "Iter: 63900; D loss: 0.01305; G_loss: -0.01867\n",
      "Iter: 64000; D loss: 0.01473; G_loss: -0.01448\n",
      "Iter: 64100; D loss: 0.01392; G_loss: -0.01406\n",
      "Iter: 64200; D loss: 0.01529; G_loss: -0.01465\n",
      "Iter: 64300; D loss: 0.0141; G_loss: -0.01365\n",
      "Iter: 64400; D loss: 0.01485; G_loss: -0.01611\n",
      "Iter: 64500; D loss: 0.01557; G_loss: -0.01548\n",
      "Iter: 64600; D loss: 0.01358; G_loss: -0.01731\n",
      "Iter: 64700; D loss: 0.01523; G_loss: -0.01612\n",
      "Iter: 64800; D loss: 0.01361; G_loss: -0.01357\n",
      "Iter: 64900; D loss: 0.01456; G_loss: -0.01635\n",
      "Iter: 65000; D loss: 0.009663; G_loss: -0.01615\n",
      "Iter: 65100; D loss: 0.01306; G_loss: -0.0126\n",
      "Iter: 65200; D loss: 0.01628; G_loss: -0.0195\n",
      "Iter: 65300; D loss: 0.01523; G_loss: -0.01616\n",
      "Iter: 65400; D loss: 0.01857; G_loss: -0.01856\n",
      "Iter: 65500; D loss: 0.01539; G_loss: -0.01517\n",
      "Iter: 65600; D loss: 0.01674; G_loss: -0.01757\n",
      "Iter: 65700; D loss: 0.01598; G_loss: -0.01252\n",
      "Iter: 65800; D loss: 0.01575; G_loss: -0.01822\n",
      "Iter: 65900; D loss: 0.01441; G_loss: -0.01948\n",
      "Iter: 66000; D loss: 0.0158; G_loss: -0.01725\n",
      "Iter: 66100; D loss: 0.01527; G_loss: -0.01508\n",
      "Iter: 66200; D loss: 0.01312; G_loss: -0.01812\n",
      "Iter: 66300; D loss: 0.01399; G_loss: -0.01506\n",
      "Iter: 66400; D loss: 0.01077; G_loss: -0.01937\n",
      "Iter: 66500; D loss: 0.0141; G_loss: -0.01494\n",
      "Iter: 66600; D loss: 0.01755; G_loss: -0.0216\n",
      "Iter: 66700; D loss: 0.01314; G_loss: -0.01817\n",
      "Iter: 66800; D loss: 0.01238; G_loss: -0.01692\n",
      "Iter: 66900; D loss: 0.01741; G_loss: -0.01553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 67000; D loss: 0.01795; G_loss: -0.01541\n",
      "Iter: 67100; D loss: 0.01412; G_loss: -0.02351\n",
      "Iter: 67200; D loss: 0.01494; G_loss: -0.01755\n",
      "Iter: 67300; D loss: 0.01456; G_loss: -0.0154\n",
      "Iter: 67400; D loss: 0.0152; G_loss: -0.01767\n",
      "Iter: 67500; D loss: 0.0191; G_loss: -0.01575\n",
      "Iter: 67600; D loss: 0.01281; G_loss: -0.02138\n",
      "Iter: 67700; D loss: 0.01629; G_loss: -0.02018\n",
      "Iter: 67800; D loss: 0.01238; G_loss: -0.01433\n",
      "Iter: 67900; D loss: 0.01712; G_loss: -0.01549\n",
      "Iter: 68000; D loss: 0.01921; G_loss: -0.02306\n",
      "Iter: 68100; D loss: 0.01529; G_loss: -0.01915\n",
      "Iter: 68200; D loss: 0.01386; G_loss: -0.01847\n",
      "Iter: 68300; D loss: 0.01805; G_loss: -0.01503\n",
      "Iter: 68400; D loss: 0.01442; G_loss: -0.01817\n",
      "Iter: 68500; D loss: 0.01168; G_loss: -0.01456\n",
      "Iter: 68600; D loss: 0.01436; G_loss: -0.01443\n",
      "Iter: 68700; D loss: 0.01431; G_loss: -0.0165\n",
      "Iter: 68800; D loss: 0.01365; G_loss: -0.01443\n",
      "Iter: 68900; D loss: 0.01436; G_loss: -0.02231\n",
      "Iter: 69000; D loss: 0.01767; G_loss: -0.01844\n",
      "Iter: 69100; D loss: 0.01106; G_loss: -0.01903\n",
      "Iter: 69200; D loss: 0.01136; G_loss: -0.01619\n",
      "Iter: 69300; D loss: 0.01284; G_loss: -0.01734\n",
      "Iter: 69400; D loss: 0.01202; G_loss: -0.01359\n",
      "Iter: 69500; D loss: 0.01545; G_loss: -0.01751\n",
      "Iter: 69600; D loss: 0.01293; G_loss: -0.01503\n",
      "Iter: 69700; D loss: 0.01327; G_loss: -0.01947\n",
      "Iter: 69800; D loss: 0.01601; G_loss: -0.02026\n",
      "Iter: 69900; D loss: 0.0127; G_loss: -0.0181\n",
      "Iter: 70000; D loss: 0.01671; G_loss: -0.01793\n",
      "Iter: 70100; D loss: 0.01341; G_loss: -0.02016\n",
      "Iter: 70200; D loss: 0.01167; G_loss: -0.0139\n",
      "Iter: 70300; D loss: 0.0141; G_loss: -0.01414\n",
      "Iter: 70400; D loss: 0.01356; G_loss: -0.01574\n",
      "Iter: 70500; D loss: 0.01365; G_loss: -0.01668\n",
      "Iter: 70600; D loss: 0.01669; G_loss: -0.01936\n",
      "Iter: 70700; D loss: 0.01788; G_loss: -0.01467\n",
      "Iter: 70800; D loss: 0.01294; G_loss: -0.02228\n",
      "Iter: 70900; D loss: 0.01346; G_loss: -0.01706\n",
      "Iter: 71000; D loss: 0.01274; G_loss: -0.01683\n",
      "Iter: 71100; D loss: 0.0171; G_loss: -0.01849\n",
      "Iter: 71200; D loss: 0.0135; G_loss: -0.01376\n",
      "Iter: 71300; D loss: 0.01151; G_loss: -0.02004\n",
      "Iter: 71400; D loss: 0.013; G_loss: -0.01597\n",
      "Iter: 71500; D loss: 0.01607; G_loss: -0.02015\n",
      "Iter: 71600; D loss: 0.01468; G_loss: -0.01689\n",
      "Iter: 71700; D loss: 0.01442; G_loss: -0.01766\n",
      "Iter: 71800; D loss: 0.01768; G_loss: -0.01599\n",
      "Iter: 71900; D loss: 0.01458; G_loss: -0.01473\n",
      "Iter: 72000; D loss: 0.01708; G_loss: -0.02038\n",
      "Iter: 72100; D loss: 0.01274; G_loss: -0.01438\n",
      "Iter: 72200; D loss: 0.01417; G_loss: -0.01553\n",
      "Iter: 72300; D loss: 0.01297; G_loss: -0.01759\n",
      "Iter: 72400; D loss: 0.01192; G_loss: -0.01786\n",
      "Iter: 72500; D loss: 0.01599; G_loss: -0.01439\n",
      "Iter: 72600; D loss: 0.01578; G_loss: -0.01623\n",
      "Iter: 72700; D loss: 0.01333; G_loss: -0.02108\n",
      "Iter: 72800; D loss: 0.01713; G_loss: -0.02082\n",
      "Iter: 72900; D loss: 0.01209; G_loss: -0.0146\n",
      "Iter: 73000; D loss: 0.01374; G_loss: -0.02051\n",
      "Iter: 73100; D loss: 0.01347; G_loss: -0.01586\n",
      "Iter: 73200; D loss: 0.01548; G_loss: -0.01715\n",
      "Iter: 73300; D loss: 0.01803; G_loss: -0.02189\n",
      "Iter: 73400; D loss: 0.01422; G_loss: -0.01192\n",
      "Iter: 73500; D loss: 0.01428; G_loss: -0.0153\n",
      "Iter: 73600; D loss: 0.01506; G_loss: -0.01541\n",
      "Iter: 73700; D loss: 0.01498; G_loss: -0.01737\n",
      "Iter: 73800; D loss: 0.01365; G_loss: -0.01615\n",
      "Iter: 73900; D loss: 0.01582; G_loss: -0.0211\n",
      "Iter: 74000; D loss: 0.01793; G_loss: -0.01486\n",
      "Iter: 74100; D loss: 0.01142; G_loss: -0.01817\n",
      "Iter: 74200; D loss: 0.01574; G_loss: -0.01847\n",
      "Iter: 74300; D loss: 0.009841; G_loss: -0.0153\n",
      "Iter: 74400; D loss: 0.01342; G_loss: -0.01661\n",
      "Iter: 74500; D loss: 0.01808; G_loss: -0.02207\n",
      "Iter: 74600; D loss: 0.01785; G_loss: -0.01977\n",
      "Iter: 74700; D loss: 0.0128; G_loss: -0.01861\n",
      "Iter: 74800; D loss: 0.01367; G_loss: -0.01397\n",
      "Iter: 74900; D loss: 0.01229; G_loss: -0.01518\n",
      "Iter: 75000; D loss: 0.01712; G_loss: -0.02216\n",
      "Iter: 75100; D loss: 0.01367; G_loss: -0.01904\n",
      "Iter: 75200; D loss: 0.01085; G_loss: -0.0218\n",
      "Iter: 75300; D loss: 0.0143; G_loss: -0.01701\n",
      "Iter: 75400; D loss: 0.0165; G_loss: -0.01784\n",
      "Iter: 75500; D loss: 0.01555; G_loss: -0.01683\n",
      "Iter: 75600; D loss: 0.01458; G_loss: -0.01329\n",
      "Iter: 75700; D loss: 0.01468; G_loss: -0.02003\n",
      "Iter: 75800; D loss: 0.01342; G_loss: -0.01561\n",
      "Iter: 75900; D loss: 0.01257; G_loss: -0.01659\n",
      "Iter: 76000; D loss: 0.01196; G_loss: -0.01857\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "\n",
    "\n",
    "mb_size = 32\n",
    "X_dim = 784\n",
    "z_dim = 10\n",
    "h_dim = 128\n",
    "\n",
    "mnist = input_data.read_data_sets('./data/mnist', one_hot=True)\n",
    "\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([h_dim, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]\n",
    "\n",
    "\n",
    "z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]\n",
    "\n",
    "\n",
    "def sample_z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "\n",
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "    return G_prob\n",
    "\n",
    "\n",
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    out = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    return out\n",
    "\n",
    "\n",
    "G_sample = generator(z)\n",
    "D_real = discriminator(X)\n",
    "D_fake = discriminator(G_sample)\n",
    "\n",
    "D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)\n",
    "G_loss = -tf.reduce_mean(D_fake)\n",
    "\n",
    "D_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)\n",
    "            .minimize(-D_loss, var_list=theta_D))\n",
    "G_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)\n",
    "            .minimize(G_loss, var_list=theta_G))\n",
    "\n",
    "# tf.clip_by_value(V, min, max), 截取V使之在min和max之间\n",
    "clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in theta_D]\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('outWGAN/'):\n",
    "    os.makedirs('outWGAN/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(1000000):\n",
    "    for _ in range(5):\n",
    "        X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "\n",
    "        _, D_loss_curr, _ = sess.run(\n",
    "            [D_solver, D_loss, clip_D],\n",
    "            feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)}\n",
    "        )\n",
    "\n",
    "    _, G_loss_curr = sess.run(\n",
    "        [G_solver, G_loss],\n",
    "        feed_dict={z: sample_z(mb_size, z_dim)}\n",
    "    )\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}; D loss: {:.4}; G_loss: {:.4}'\n",
    "              .format(it, D_loss_curr, G_loss_curr))\n",
    "\n",
    "        if it % 1000 == 0:\n",
    "            samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})\n",
    "\n",
    "            fig = plot(samples)\n",
    "            plt.savefig('out/{}.png'\n",
    "                        .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "            i += 1\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
