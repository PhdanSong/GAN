{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN相比于GAN的改进之处:\n",
    "\n",
    "# 使用了LeakRelu 激活函数, 经过大牛的实验证明效果好于Relu\n",
    "# 使用batchnormalization, 有效减少了随机初始化带来的误差\n",
    "# 判别网络中使用了strides convolutions 代替了池化操作, 生成器中使用fractional strided convolutions (反卷积)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/hadoop/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c9a6c867a472>:20: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /data1/hadoop/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /data1/hadoop/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /data1/hadoop/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /data1/hadoop/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Epoch 1/5... stpes:5  Discriminator loss : 1.2483... Generator loss: 9.1619\n",
      "Epoch 1/5... stpes:10  Discriminator loss : 0.7006... Generator loss: 9.6206\n",
      "Epoch 1/5... stpes:15  Discriminator loss : 0.5862... Generator loss: 5.2889\n",
      "Epoch 1/5... stpes:20  Discriminator loss : 0.4985... Generator loss: 5.7055\n",
      "Epoch 1/5... stpes:25  Discriminator loss : 0.5072... Generator loss: 8.9635\n",
      "Epoch 1/5... stpes:30  Discriminator loss : 0.4780... Generator loss: 7.8247\n",
      "Epoch 1/5... stpes:35  Discriminator loss : 0.4341... Generator loss: 6.3075\n",
      "Epoch 1/5... stpes:40  Discriminator loss : 0.4818... Generator loss: 6.0312\n",
      "Epoch 1/5... stpes:45  Discriminator loss : 0.4028... Generator loss: 5.7872\n",
      "Epoch 1/5... stpes:50  Discriminator loss : 0.3924... Generator loss: 5.9369\n",
      "Epoch 1/5... stpes:55  Discriminator loss : 0.3872... Generator loss: 7.6637\n",
      "Epoch 1/5... stpes:60  Discriminator loss : 0.4219... Generator loss: 5.1295\n",
      "Epoch 1/5... stpes:65  Discriminator loss : 0.4064... Generator loss: 6.0983\n",
      "Epoch 1/5... stpes:70  Discriminator loss : 0.3867... Generator loss: 6.3957\n",
      "Epoch 1/5... stpes:75  Discriminator loss : 0.4449... Generator loss: 5.5522\n",
      "Epoch 1/5... stpes:80  Discriminator loss : 0.3911... Generator loss: 6.1991\n",
      "Epoch 1/5... stpes:85  Discriminator loss : 0.3786... Generator loss: 5.3328\n",
      "Epoch 1/5... stpes:90  Discriminator loss : 0.4325... Generator loss: 4.5405\n",
      "Epoch 1/5... stpes:95  Discriminator loss : 0.4208... Generator loss: 4.5551\n",
      "Epoch 1/5... stpes:100  Discriminator loss : 0.3852... Generator loss: 5.5007\n",
      "Epoch 1/5... stpes:105  Discriminator loss : 0.4490... Generator loss: 6.5119\n",
      "Epoch 1/5... stpes:110  Discriminator loss : 0.4146... Generator loss: 5.5820\n",
      "Epoch 1/5... stpes:115  Discriminator loss : 0.3949... Generator loss: 5.6901\n",
      "Epoch 1/5... stpes:120  Discriminator loss : 0.4031... Generator loss: 6.3530\n",
      "Epoch 1/5... stpes:125  Discriminator loss : 0.4653... Generator loss: 4.3244\n",
      "Epoch 1/5... stpes:130  Discriminator loss : 0.4028... Generator loss: 6.1629\n",
      "Epoch 1/5... stpes:135  Discriminator loss : 0.4001... Generator loss: 6.1579\n",
      "Epoch 1/5... stpes:140  Discriminator loss : 0.3941... Generator loss: 7.2425\n",
      "Epoch 1/5... stpes:145  Discriminator loss : 0.4673... Generator loss: 6.0606\n",
      "Epoch 1/5... stpes:150  Discriminator loss : 0.4051... Generator loss: 5.1351\n",
      "Epoch 1/5... stpes:155  Discriminator loss : 0.4097... Generator loss: 6.4445\n",
      "Epoch 1/5... stpes:160  Discriminator loss : 0.3986... Generator loss: 6.0596\n",
      "Epoch 1/5... stpes:165  Discriminator loss : 0.4013... Generator loss: 6.0624\n",
      "Epoch 1/5... stpes:170  Discriminator loss : 0.3675... Generator loss: 5.8095\n",
      "Epoch 1/5... stpes:175  Discriminator loss : 0.3787... Generator loss: 4.4542\n",
      "Epoch 1/5... stpes:180  Discriminator loss : 0.4039... Generator loss: 4.9459\n",
      "Epoch 1/5... stpes:185  Discriminator loss : 0.3923... Generator loss: 5.0524\n",
      "Epoch 1/5... stpes:190  Discriminator loss : 0.3861... Generator loss: 5.8777\n",
      "Epoch 1/5... stpes:195  Discriminator loss : 0.3848... Generator loss: 5.2438\n",
      "Epoch 1/5... stpes:200  Discriminator loss : 0.3834... Generator loss: 6.8237\n",
      "Epoch 1/5... stpes:205  Discriminator loss : 0.4158... Generator loss: 7.2388\n",
      "Epoch 1/5... stpes:210  Discriminator loss : 0.3695... Generator loss: 6.7126\n",
      "Epoch 1/5... stpes:215  Discriminator loss : 0.3853... Generator loss: 5.9255\n",
      "Epoch 1/5... stpes:220  Discriminator loss : 0.3686... Generator loss: 5.0126\n",
      "Epoch 1/5... stpes:225  Discriminator loss : 0.3838... Generator loss: 4.4932\n",
      "Epoch 1/5... stpes:230  Discriminator loss : 0.4036... Generator loss: 4.4704\n",
      "Epoch 1/5... stpes:235  Discriminator loss : 0.3693... Generator loss: 5.3428\n",
      "Epoch 1/5... stpes:240  Discriminator loss : 0.3797... Generator loss: 5.6549\n",
      "Epoch 1/5... stpes:245  Discriminator loss : 0.3938... Generator loss: 4.9087\n",
      "Epoch 1/5... stpes:250  Discriminator loss : 0.4116... Generator loss: 4.0378\n",
      "Epoch 1/5... stpes:255  Discriminator loss : 0.5145... Generator loss: 5.0060\n",
      "Epoch 1/5... stpes:260  Discriminator loss : 0.4391... Generator loss: 4.3132\n",
      "Epoch 1/5... stpes:265  Discriminator loss : 0.3641... Generator loss: 4.8219\n",
      "Epoch 1/5... stpes:270  Discriminator loss : 0.4179... Generator loss: 5.6384\n",
      "Epoch 1/5... stpes:275  Discriminator loss : 0.3761... Generator loss: 4.4788\n",
      "Epoch 1/5... stpes:280  Discriminator loss : 0.3820... Generator loss: 4.3654\n",
      "Epoch 1/5... stpes:285  Discriminator loss : 0.3641... Generator loss: 4.8474\n",
      "Epoch 1/5... stpes:290  Discriminator loss : 0.3621... Generator loss: 4.3901\n",
      "Epoch 1/5... stpes:295  Discriminator loss : 0.3570... Generator loss: 5.1051\n"
     ]
    }
   ],
   "source": [
    "#代码附详细注释\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 定义几个超参数, batch-size的大小\n",
    "batch_size = 64\n",
    "# 噪声的长度\n",
    "noise_size = 100\n",
    "# 迭代的轮数\n",
    "epochs = 5\n",
    "# 学习率\n",
    "learning_rate = 0.001\n",
    "# 抽取样本检查生成器的性能\n",
    "n_smples = 20\n",
    "\n",
    "# 读取mnist数据集\n",
    "mnist = input_data.read_data_sets('./data/mnist')\n",
    "\n",
    "# 获取生成网络和判别网络的输入\n",
    "def get_input(noise_dim, image_height, image_width, image_depth):\n",
    "    \"\"\"\n",
    "    :param noise_dim: 噪声的长度\n",
    "    :param image_height: 图片的高度\n",
    "    :param image_width: 图片的宽度\n",
    "    :param image_depth: 图片的深度\n",
    "    :return: 以placeholder形式返回两个网络的输入\n",
    "    \"\"\"\n",
    "    D_input = tf.placeholder(tf.float32, [None, image_height, image_width, image_depth], name=\"input_real\")\n",
    "    G_input = tf.placeholder(tf.float32, [None, noise_dim], name=\"input_noise\")\n",
    "\n",
    "    return D_input, G_input\n",
    "\n",
    "# 定义生成器\n",
    "def get_generator(G_input, output_dim, is_train=True, alpha=0.01):\n",
    "    \"\"\"\n",
    "    :param G_input: 生成器的输入,应该是(batch_size, 100)\n",
    "    :param output_dim: 生成器的输出, (batch_size, 28, 28, 1)\n",
    "    :param is_train: 是否训练\n",
    "    :param alpha: LeakyRelu的参数\n",
    "    :return: 返回生成的图片\n",
    "    \"\"\"\n",
    "    # 定义一个命名空间generator\n",
    "    with tf.variable_scope(\"generator\", reuse=(not is_train)):\n",
    "        # batch x 100 x 1 ---> batch x 4 x 4 x 512\n",
    "        layer1 = tf.layers.dense(G_input, 4*4*512)\n",
    "        layer1 = tf.reshape(layer1, [-1, 4, 4, 512])\n",
    "        layer1 = tf.layers.batch_normalization(layer1, training=is_train)\n",
    "        layer1 = tf.maximum(alpha * layer1, layer1)\n",
    "        layer1 = tf.nn.dropout(layer1, keep_prob=0.6)\n",
    "\n",
    "        # batch x 4 x 4 x 512 ---> batch x 7 x 7 x 256\n",
    "        layer2 = tf.layers.conv2d_transpose(layer1, 256, 4, strides=1, padding=\"valid\")\n",
    "        layer2 = tf.layers.batch_normalization(layer2, training=is_train)\n",
    "        layer2 = tf.maximum(alpha * layer2, layer2)\n",
    "        layer2 = tf.nn.dropout(layer2, keep_prob=0.6)\n",
    "\n",
    "        # batch x 7 x 7 x 256 ---> batch x 14 x 14 x 128\n",
    "        layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding=\"same\")\n",
    "        layer3 = tf.layers.batch_normalization(layer3, training=is_train)\n",
    "        layer3 = tf.maximum(alpha * layer3, layer3)\n",
    "        layer3 = tf.nn.dropout(layer3, keep_prob=0.6)\n",
    "\n",
    "        # batch x 14 x 14 x 128 ---> batch x 28 x 28 x 1\n",
    "        logits = tf.layers.conv2d_transpose(layer3, output_dim, 3, strides=2, padding=\"same\")\n",
    "        outputs = tf.tanh(logits)\n",
    "        return outputs\n",
    "# 定义一个判别器\n",
    "def get_discriminator(D_input, reuse=False, alpha=0.01):\n",
    "    \"\"\"\n",
    "    :param D_input: 输入图片\n",
    "    :param reuse: 是否重用参数\n",
    "    :param alpha: LeakyRelu的参数\n",
    "    :return: 返回对图片的判别结果,是一个概率值\n",
    "    \"\"\"\n",
    "    # 定义一个命名空间discriminator\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "        # batch x 28 x 28 x 1 ---> batch x 14 x 14 x 128\n",
    "        layer1 = tf.layers.conv2d(D_input, 128, 3, strides=2, padding=\"same\")\n",
    "        layer1 = tf.maximum(alpha * layer1, layer1)\n",
    "        layer1 = tf.nn.dropout(layer1, keep_prob=0.6)\n",
    "\n",
    "        # batch x 14 x 14 x 28 ---> batch x 7 x 7 x 256\n",
    "        layer2 = tf.layers.conv2d(layer1, 256, 3, strides=2, padding=\"same\")\n",
    "        layer2 = tf.layers.batch_normalization(layer2, training=True)\n",
    "        layer2 = tf.maximum(alpha * layer2, layer2)\n",
    "        layer2 = tf.nn.dropout(layer2, keep_prob=0.6)\n",
    "\n",
    "        # batch x 7 x 7 x 256 ---> batch x 4 x 4 x 512\n",
    "        layer3 = tf.layers.conv2d(layer2, 512, 3, strides=2, padding='same')\n",
    "        layer3 = tf.layers.batch_normalization(layer3, training=True)\n",
    "        layer3 = tf.maximum(alpha * layer3, layer3)\n",
    "        layer3 = tf.nn.dropout(layer3, keep_prob=0.6)\n",
    "\n",
    "        # batch x 4 x 4 x 512 ---> batch x (16*512)\n",
    "        flatten = tf.reshape(layer3, (-1, 16*512))\n",
    "        logits = tf.layers.dense(flatten, 1)\n",
    "        outputs = tf.sigmoid(logits)\n",
    "\n",
    "        return logits, outputs\n",
    "\n",
    "# 获取模型的损失值\n",
    "def get_loss(D_input_real, G_input, image_depth, smooth=0.1):\n",
    "    \"\"\"\n",
    "    :param D_input: 判别模型的输入\n",
    "    :param G_input: 生成模型的输入\n",
    "    :param image_depth: 图片的通道数,彩色为3,灰度为1\n",
    "    :param smooth: 平滑值\n",
    "    :return: 返回两个网络的损失\n",
    "    \"\"\"\n",
    "    g_outputs = get_generator(G_input, image_depth, is_train=True)\n",
    "\n",
    "    # 将真实的图片放入模型中判别\n",
    "    d_logits_real, d_output_real = get_discriminator(D_input_real)\n",
    "\n",
    "    # 将生成器生成的图片放入判别模型中判读\n",
    "    d_logits_fake, d_output_fake = get_discriminator(g_outputs, reuse=True)\n",
    "\n",
    "    #计算损失, 生成器努力让图片更加逼真\n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                    labels=tf.ones_like(d_logits_fake)*(1-smooth)))\n",
    "\n",
    "    # 判别器努力分别出真实图片和生成图片,所以判别器的损失函数是两部分\n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                                                         labels=tf.ones_like(d_logits_real)*(1-smooth)))\n",
    "\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                         labels=tf.zeros_like(d_logits_fake)))\n",
    "    # 判别器的损失\n",
    "    d_loss = tf.add(d_loss_fake, d_loss_real)\n",
    "    # 返回损失\n",
    "    return g_loss, d_loss\n",
    "\n",
    "# 优化操作\n",
    "def get_optimizer(g_loss, d_loss, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    :param g_loss: 生成器的损失\n",
    "    :param d_loss: 判别器的损失\n",
    "    :param learning_rate: 学习率\n",
    "    :return: 优化操作\n",
    "    \"\"\"\n",
    "    # 分别通过tftrainable-variables()获得两个网络中的参数\n",
    "    train_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in train_vars if var.name.startswith(\"generator\")]\n",
    "    d_vars = [var for var in train_vars if var.name.startswith(\"discriminator\")]\n",
    "\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "    # 返回优化操作\n",
    "    return g_opt, d_opt\n",
    "\n",
    "# 训练模型\n",
    "def train(noise_size, data_shape, batch_size, n_samples):\n",
    "    \"\"\"\n",
    "    :param noise_size: 噪声的维度\n",
    "    :param data_shape: 图片的形状\n",
    "    :param batch_size: 每个batch的大小\n",
    "    :param n_samples: 抽样数目\n",
    "    \"\"\"\n",
    "    # 计步器\n",
    "    steps = 0\n",
    "    # 调用get_input()函数,从而获得两个网络的输入(placeholder形式)\n",
    "    D_input, G_input = get_input(noise_size, data_shape[1], data_shape[2], data_shape[3])\n",
    "\n",
    "    # 获取损失值\n",
    "    g_loss, d_loss = get_loss(D_input, G_input, data_shape[-1])\n",
    "    # 获取优化操作\n",
    "    g_train_opt, d_train_opt = get_optimizer(g_loss, d_loss, learning_rate)\n",
    "\n",
    "    # 打开一个会话\n",
    "    with tf.Session() as sess:\n",
    "        # 初始化所有的变量\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(mnist.train.num_examples // batch_size):\n",
    "                steps += 1\n",
    "                # 获取真实图片\n",
    "                batch = mnist.train.next_batch(batch_size)\n",
    "                batch_images = batch[0].reshape((batch_size, data_shape[1], data_shape[2], data_shape[3]))\n",
    "\n",
    "\n",
    "                # 生成噪音\n",
    "                batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size))\n",
    "                # 开始优化\n",
    "                sess.run(g_train_opt, feed_dict={D_input: batch_images,\n",
    "                                                 G_input: batch_noise})\n",
    "                sess.run(d_train_opt, feed_dict={D_input: batch_images,\n",
    "\n",
    "                                                 G_input: batch_noise})\n",
    "                # 每间隔5步打印出结果, 并且保存生成模型生成的图片\n",
    "                if steps % 5 == 0:\n",
    "                    train_loss_d = d_loss.eval({D_input: batch_images,\n",
    "                                                G_input: batch_noise})\n",
    "\n",
    "                    train_loss_g = g_loss.eval({D_input: batch_images,\n",
    "                                                G_input: batch_noise})\n",
    "\n",
    "                    # 保存生成的图片\n",
    "                    temp = tf.placeholder(tf.float32, [None, 100])\n",
    "                    sample_input_noise= np.random.uniform(-1, 1, size=(n_smples, noise_size))\n",
    "                    generator_pictures = sess.run(get_generator(temp, 1, is_train=False), feed_dict={\n",
    "                                                  temp:sample_input_noise})\n",
    "\n",
    "\n",
    "                    # 从生成的图片中随机的选取一张保存下来\n",
    "                    single_picture = generator_pictures[np.random.randint(0, n_samples)]\n",
    "                    single_picture = (np.reshape(single_picture, (28, 28)) + 1) * 127.5\n",
    "                    # 保存图片\n",
    "\n",
    "                    if not os.path.exists('DC_pictures/'):\n",
    "                        os.makedirs('DC_pictures/')\n",
    "                    cv2.imwrite(\"DC_pictures/A{}.jpg\".format(str(steps)), single_picture)\n",
    "                    print(\n",
    "                        \"Epoch {}/{}... stpes:{} \".format(epoch + 1, epochs, steps),\n",
    "                        \"Discriminator loss : {:.4f}...\".format(train_loss_d),\n",
    "                        \"Generator loss: {:.4f}\".format(train_loss_g)\n",
    "                    )\n",
    "if __name__ == '__main__':\n",
    "    with tf.Graph().as_default():\n",
    "        train(noise_size, [-1, 28, 28, 1], batch_size, n_samples=n_smples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
